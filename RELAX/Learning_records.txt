=============== RELAX model_paths ===============

(Undersampling_rate: 3, Center_fraction: 0.05, Num_Echoes: 16) # LOW undersampling rate
(Final estimation block of Res-UNet is slightly different)
(Wavelet + TV constraints applied)
1. [Regularizer_weights: 0.01, 0.01], [LR:0.0002, gamma:0.95] (First 200 epochs) # Simple implementation of WVLT transform
2. [Regularizer_weights: 0.01, 0.01], [LR:0.0002, gamma:0.95] (First 200 epochs) # CNN implementation of learnable WVLT
3. [Regularizer_weights: 1e-4, 1e-4], [LR:0.0002, gamma:0.95] (First 200 epochs) # Larger initial T2, weighted LOSS (focus on larger TEs)
4. [Regularizer_weights: 0.01, 0.01], [LR:0.0002, gamma:0.95] (First 200 epochs) # NO clamping on MAX values, TEs modified
5. [Regularizer_weights: 0.01, 0.01], [LR:0.0002, gamma:0.95] (First 200 epochs) # NO clamping on MAX values, TEs modified